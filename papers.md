# Papers

The year column represents publishing year in arxiv and not the year of latest revision. `Supplementary` pdf/docs is mostly not included in the links below. A paper may fall into multiple categories but organized into a general one.

Adding only papers worth implementing, important concepts that can be applied in future with high quality or need to be revisited again with easy to understand, SOTA, close to SOTA results or unique ideas. Not adding paper if concept not understood, too hard or anything meaningful not found.

<!--
|  |  |
| <h3></h3> |  |
-->

## Papers Read

- :triangular_flag_on_post: Represents overall good understanding, easier to understand with diagrams, examples or good explanation simple language.

| Topic | Year |
| --- | --- |
| <h3>Uncategorized</h3> |  |
| [Feature Pyramid Networks for Object Detection (FPN)](https://arxiv.org/abs/1612.03144) | 2016 | 
| [COIN: COmpression with Implicit Neural representations](https://arxiv.org/abs/2103.03123) | 2021 |    
| [MaskGAN: Towards Diverse and Interactive Facial Image Manipulation](https://arxiv.org/abs/1907.11922) | 2019 |   
| [Attention Is All You Need](https://arxiv.org/abs/1706.03762) | 2017 |  
| [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) | 2020 |    
| [Improved Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2102.09672) | 2021 |  
| [Deep Image Prior](https://openaccess.thecvf.com/content_cvpr_2018/papers/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.pdf) <br> [Supplementary](https://openaccess.thecvf.com/content_cvpr_2018/Supplemental/2711-supp.pdf) | 2018 |  
| [Adding Conditional Control to Text-to-Image Diffusion Models](https://arxiv.org/abs/2302.05543) | 2023 |  
| [LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS](https://arxiv.org/abs/2106.09685) | 2021 |  
|  |  |
| <h3>Vision Transformers</h3> |  |
| :triangular_flag_on_post: [AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE <br> (Vision Transformer, ViT)](https://arxiv.org/abs/2010.11929) | 2020 |  
|  |  |
| <h3>Knowledge Distillation</h3> |  |
| :triangular_flag_on_post: [Distilling the Knowledge in a Neural Network (Knowledge Distillation)](https://arxiv.org/abs/1503.02531) | 2015 |  
| :triangular_flag_on_post: [On the Efficacy of Knowledge Distillation](https://openaccess.thecvf.com/content_ICCV_2019/papers/Cho_On_the_Efficacy_of_Knowledge_Distillation_ICCV_2019_paper.pdf) | 2019 |  |  
|  |  |
| <h3>Object Recognition, Clutering, Verification</h3> |  |
| :triangular_flag_on_post: [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832.pdf) | 2015 |  
| :triangular_flag_on_post: [Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf) | 2015 |  
|  |  |
| <h3>Image Captioning</h3> |  |
| [Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge](https://arxiv.org/abs/1609.06647) | 2016 |  
|  |  |
| <h3>Text to Image Generation</h3> |  |
| [Zero-Shot Text-to-Image Generation (DALL-E)](https://arxiv.org/pdf/2102.12092.pdf) | 2021 |  
|  |  |
| <h3>Multimodal Deep Learning</h3> |  |
| [Learning Transferable Visual Models From Natural Language Supervision (CLIP)](https://arxiv.org/pdf/2103.00020.pdf) | 2021 |  
|  |  |
| <h3>Image Super Resolution</h3> |  |
| [Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network (SRGAN)](https://arxiv.org/abs/1609.04802) | 2016 |  
|  |  |
| <h3>Image Segmentation</h3> |  |
| [U-Net: Convolutional Networks for Biomedical Image Segmentation (UNet)](https://arxiv.org/abs/1505.04597) | 2015 |  
|  |  |
| <h3>Convolutional Neural Network (CNN) Architectures</h3> |  |
| [ImageNet Classification with Deep Convolutional Neural Networks (AlexNet)](https://www.cs.toronto.edu/~kriz/imagenet_classification_with_deep_convolutional.pdf) | 2012 |  
| [Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning](https://arxiv.org/abs/1602.07261) | 2016 |  
| [Going deeper with convolutions (Inception/GoogLeNet)](https://arxiv.org/abs/1409.4842) | 2014 |  
| [VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION (VGG)](https://arxiv.org/abs/1409.1556) | 2014 |  
| :triangular_flag_on_post: [Wide Residual Networks (WRN)](https://arxiv.org/abs/1605.07146) | 2016 |  
| :triangular_flag_on_post: [Deep Residual Learning for Image Recognition (ResNet)](https://arxiv.org/pdf/1512.03385.pdf) | 2015 |  
| :triangular_flag_on_post: [Aggregated Residual Transformations for Deep Neural Networks (ResNeXt)](https://arxiv.org/abs/1611.05431) | 2016 |  
|  |  |
| <h3>Survey/Review Papers</h3> |  |
| [GAN Inversion: A Survey](https://arxiv.org/abs/2101.05278) | 2021 |  
|  |  |
| <h3>Generative Adversarial Network (GAN)</h3> |  |
| [Generative Adversarial Networks (GANs)](https://arxiv.org/abs/1406.2661) | 2014 |  
| [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks (DCGAN)](https://arxiv.org/abs/1511.06434) | 2015 |  
| [Improved Training of Wasserstein GANs (WGAN-GP)](https://arxiv.org/abs/1704.00028) | 2017 |   
| [Conditional Generative Adversarial Nets](https://arxiv.org/abs/1411.1784) | 2014 |  
| :triangular_flag_on_post: [Analyzing and Improving the Image Quality of StyleGAN (StyleGAN 2)](https://arxiv.org/pdf/1912.04958.pdf) | 2019 |  
| :triangular_flag_on_post: [Training Generative Adversarial Networks with Limited Data (StyleGAN 2 ADA)](https://arxiv.org/pdf/2006.06676.pdf) | 2020 |  
| :triangular_flag_on_post: [Alias-Free Generative Adversarial Networks (StyleGAN 3)](https://nvlabs-fi-cdn.nvidia.com/stylegan3/stylegan3-paper.pdf) | 2021 |  
| :triangular_flag_on_post: [PROGRESSIVE GROWING OF GANS FOR IMPROVED QUALITY, STABILITY, AND VARIATION (ProGAN)](https://arxiv.org/abs/1710.10196) | 2017 |  
| :triangular_flag_on_post: [A Style-Based Generator Architecture for Generative Adversarial Networks (StyleGAN)](https://arxiv.org/pdf/1812.04948.pdf) | 2018 |  
|  |  |
| <h3>Image to Image Translation</h3> |  |
| [Image-to-Image Translation with Conditional Adversarial Networks (pix2pix)](https://arxiv.org/abs/1611.07004) | 2016 |  
| [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks (CycleGAN)](https://arxiv.org/abs/1703.10593) | 2017 |  
| :triangular_flag_on_post: [Semantic Image Synthesis with Spatially-Adaptive Normalization (GauGAN/SPADE)](https://arxiv.org/abs/1903.07291) | 2019 |
|  |  |
| <h3>Neural Style Transfer (NST)</h3> |  |
| [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576) <br> [Image Style Transfer Using Convolutional Neural Networks](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Gatys_Image_Style_Transfer_CVPR_2016_paper.pdf) | 2016 <br> 2015 | 
| :triangular_flag_on_post: [Perceptual Losses for Real-Time Style Transfer and Super-Resolution](https://arxiv.org/abs/1603.08155) <br> :triangular_flag_on_post: [Supplementary](https://cs.stanford.edu/people/jcjohns/papers/fast-style/fast-style-supp.pdf) | 2016 |  
|  |  |
| <h3>Language Models</h3> |  |
| :triangular_flag_on_post: [Improving Language Understanding by Generative Pre-Training (GPT)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf) | 2018 |
| :triangular_flag_on_post: [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (BERT)](https://arxiv.org/abs/1810.04805) | 2018 |  
| [Language Models are Unsupervised Multitask Learners (GPT-2)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) | 2019 |

<br>

## Reading List

| Topic | Year | 
| --- | --- | 
| [SELF-ATTENTION DOES NOT NEED O(n^2) MEMORY](https://arxiv.org/pdf/2112.05682v2.pdf) |  |  
| [Attention Mechanisms in Computer Vision: A Survey](https://arxiv.org/pdf/2111.07624v1.pdf) |  |  

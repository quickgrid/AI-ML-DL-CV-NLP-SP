# [AI Notes](https://github.com/quickgrid/AI-Resources/blob/master/ai-notes.md)

Notes from reading various deep learning, computer vision etc. papers. 

Many of the text are copied from paper verbatim, others with some modifications and rephrasing. Figures are from paper. Highlighted portions should be read and only some of the highlighted parts are expanded as notes.

**WARNING:** These notes may contain errors due to misinterpretation, lack of understanding, missing details etc. 

### TODO

- Fill in important highlighted missing details.

# Vision Transformer Family

### Papers

| Paper | Year | Conference |
| --- | --- | --- |
| [AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE (Vision Transformer, ViT)](https://arxiv.org/abs/2010.11929) | 2020 |  |

# Vision Transformer (ViT) 

## Architecture

<img src="figures/vit/vit_1.png" width=80% height=80%>

## Implementation Details

<img src="figures/vit/vit_2.png" width=80% height=80%>

<img src="figures/vit/vit_3.png" width=80% height=80%>

## Multihead Self Attention (MSA)

<img src="figures/vit/vit_4.png" width=80% height=80%>

## Axial Attention

<img src="figures/vit/vit_5.png" width=80% height=80%>
